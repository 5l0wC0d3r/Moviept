{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5l0wC0d3r/Moviept/blob/main/moviept.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzhVKPBqYKV-"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install peft\n",
        "!pip install auto-gptq\n",
        "!pip install optimum\n",
        "!pip install bitsandbytes\n",
        "!pip install transformers\n",
        "!pip install optimum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKSDfd365hQA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7axIKa4ZNlv"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from optimum.gptq import GPTQQuantizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOGfRvE3Z5jS"
      },
      "outputs": [],
      "source": [
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name = \"BAAI/bge-small-en-v1.5\")\n",
        "Settings.llm = None\n",
        "Settings.chunk_size = 4096\n",
        "Settings.chunk_overlap = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo0Hezy1aYeR"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"/content/drive/MyDrive/MindCase\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZC0XCTgc9J_"
      },
      "outputs": [],
      "source": [
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrR6Y9Qudnlw"
      },
      "outputs": [],
      "source": [
        "#store vectors into vector database\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAuJ0mAxdx8h"
      },
      "outputs": [],
      "source": [
        "#set number of docs to retrieve\n",
        "top_k = 3\n",
        "\n",
        "#configure retriever\n",
        "retriever = VectorIndexRetriever(index = index, similarity_top_k = top_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFJyhjS6eIjB"
      },
      "outputs": [],
      "source": [
        "#assemble query engine\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever = retriever,\n",
        "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heNsOFkLe_oP"
      },
      "outputs": [],
      "source": [
        "#load fine-tuned model from hub\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", trust_remote_code=False, revision = \"main\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1zQp-39hSJe"
      },
      "outputs": [],
      "source": [
        "config = PeftConfig.from_pretrained(\"shawhin/shawgpt-ft\")\n",
        "model = PeftModel.from_pretrained(model, \"shawhin/shawgpt-ft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H_TAiP09ROj"
      },
      "outputs": [],
      "source": [
        "from auto_gptq import exllama_set_max_input_length\n",
        "model = exllama_set_max_input_length(model, max_input_length=2800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eCsjDcLi-kX"
      },
      "outputs": [],
      "source": [
        "#load tokenizer\n",
        "tokenizer =AutoTokenizer.from_pretrained(model_name, use_fast = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1_eaU3IxX9I"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import quote_from_bytes\n",
        "query = \"Explain the theme of the movie?\"\n",
        "response = query_engine.query(query)\n",
        "\n",
        "#query documents\n",
        "context = \"Context: \\n\"\n",
        "for i in range(top_k):\n",
        "  context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
        "\n",
        "print(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0m9Sj9A0U8P"
      },
      "outputs": [],
      "source": [
        "# prompt (with context)\n",
        "prompt_template_w_context = lambda context, comment: f\"\"\"[INST]MOVIEPT, functioning as a virtual screen writer, with an expertise in Feminist Theory and related domains \\\n",
        "will help provide a detailed solution to the user's query with reference to the context provided.\n",
        "\n",
        "{context}\n",
        "Give solution the following query. Use the context above.\n",
        "\n",
        "{comment}\n",
        "[/INST]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aym28oG3yH2J"
      },
      "outputs": [],
      "source": [
        "comment = \"Explain the theme of the movie?\"\n",
        "prompt = prompt_template_w_context(context, comment)\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w11FvJbr8kOj"
      },
      "outputs": [],
      "source": [
        "print(len(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOCFGhV18vwO"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(len(inputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyZ0TlNR882A"
      },
      "outputs": [],
      "source": [
        "print(len(inputs['input_ids'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72g7AwSm1nrl"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
        "\n",
        "print(tokenizer.batch_decode(outputs)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEIHzfG499N-"
      },
      "outputs": [],
      "source": [
        "query = '''Who are the characters?'''\n",
        "\n",
        "response = query_engine.query(query)\n",
        "\n",
        "#query documents\n",
        "context = \"Context: \\n\"\n",
        "for i in range(top_k):\n",
        "  context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
        "\n",
        "prompt = prompt_template_w_context(context, query)\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJK8ltwq1uH6"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
        "\n",
        "print(tokenizer.batch_decode(outputs)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyxEucsCGWOO"
      },
      "outputs": [],
      "source": [
        "def prompter(comment):\n",
        "  #query documents\n",
        "  response = query_engine.query(comment)\n",
        "\n",
        "  context = \"Context: \\n\"\n",
        "\n",
        "  for i in range(top_k):\n",
        "    context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
        "\n",
        "  prompt = prompt_template_w_context(context, comment)\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNHjeNtlG4Yq"
      },
      "outputs": [],
      "source": [
        "query = \"How many male and female characters are in the movie?\"\n",
        "prompt = prompter(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ4HSz1nHQ3d"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=1024)\n",
        "\n",
        "print(tokenizer.batch_decode(outputs)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvW1RYQYHaMX"
      },
      "outputs": [],
      "source": [
        "def moviept(input_query):\n",
        "  input_prompt = prompter(input_query)\n",
        "\n",
        "  inputs = tokenizer(input_prompt, return_tensors=\"pt\")\n",
        "\n",
        "  outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                           attention_mask=inputs[\"attention_mask\"].to(\"cuda\"),\n",
        "                           pad_token_id=tokenizer.eos_token_id,\n",
        "                           max_new_tokens=1024)\n",
        "\n",
        "  result = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "  solution = result.split(\"[/INST]\\n\")[1].strip().replace(\"</s>\", \"\\n~MTHgpt\")\n",
        "  print(input_query + \"\\n\" + solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nvly3rZISxY"
      },
      "outputs": [],
      "source": [
        "query = \"Does the script pass the Bechdel test?\"\n",
        "moviept(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "moviept(\"Explain the theme of the movie?\")"
      ],
      "metadata": {
        "id": "dkaSX-2cv2uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moviept(\"What is the role of Deckard in the movie?\")"
      ],
      "metadata": {
        "id": "DreBkDnGwDln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moviept(\"Who are the characters?\")"
      ],
      "metadata": {
        "id": "XIbs2Tu9wJrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moviept(\"How many male and female characters are in the movie?\")"
      ],
      "metadata": {
        "id": "bnQepCqjwY5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moviept(\"Does the script pass the Bechdel test?\")"
      ],
      "metadata": {
        "id": "0WOIfTQhwbtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moviept(\"What is the role of Deckard in the movie?\")"
      ],
      "metadata": {
        "id": "Gysgt-YgwfXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}